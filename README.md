# netty 的一些简单的demo
## netty discard server
只接受连接，不响应用户输入的服务
## netty echo server
接受连接，并返回客戶端输入
## netty chart server
聊天服务，多個客戶端，通过@其他用戶進行聊天沟通

# netty 源碼解讀
## 异步非阻塞通信
java1.4之前，进行网络应用开发，使用的BIO模型进行通信，读写网络书记，往往每个连接建立，都要创建一个对应的线程，“守”在连接的读写接口，为上层业务提供数据的发送和接受；随着连接数的增多，线程数量线性增长，消耗大量的系统资源。
在jvm内存模型中，堆内存是共享内存，而每个线程的栈空间，却是与线程同生命周期的。如果线程的栈空间大小是200k，那么，5000个线程会消耗1g的内存作为栈空间使用。在BIO模型网络应用中，大部分情况下，线程都是“守”在读写接口上，这就造成，线程占用了大量的栈空间，却等在那里，没有给CPU“喂”指令，CPU的利用率自然不会高，同时栈空间也白白占用，留给运行线程的内存资源响应减少；
另外，每个连接一个线程，连接数量增加，线程数量对应增加。线程被阻塞，和被读信号唤醒的时候，会导致上下文切换，系统层面要进行额外的大量工作，将正在运行的现场保存，并调出唤醒的线程，从而保证被唤醒程序的正常运行。这个过程存在的系统开销，是大量异步线程创建之后的另一个副作用。CPU用于执行这些系统开销的时间增多，自然用于处理用户业务的时间减少；吞吐量降低。
java1.4之后，引入NIO的概念，NIO就是非阻塞IO，这种新的模型，将多个channel和一个selector绑定起来，通过对这个selector进行事件监听，就可以完成这许多channel的读写操作。而不用每个连接对应一个线程操作。在原生的java nio中，1024个连接，才启动一个线程，处理读写事件。从java栈的角度看，内存利用率提高了千倍，而线程数量的减少，更是将上下文切换占用的CPU时间大大降低，从而提升了CPU利用率。
netty正是在NIO基础上，诞生的网络应用开发框架。在原生nio基础上，进行了良好的封装，提供简洁易用的编成接口。在提供高校的网络开发能力的同时，也提供了高校的开发体验
#https://netty.io/images/components.png，
